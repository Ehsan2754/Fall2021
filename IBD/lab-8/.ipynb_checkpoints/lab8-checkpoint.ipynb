{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73111480",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcbbc3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2931316\r\n",
      "drwxrwxrwx 1 root   root        4096 Nov 24 11:06 \u001b[0m\u001b[34;42m.\u001b[0m/\r\n",
      "drwxr-xr-x 1 root   root        4096 Nov 20 11:30 \u001b[01;34m..\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan users       4096 Nov 24 11:00 \u001b[01;34m.cache\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan users       4096 Nov 24 11:04 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan users       4096 Nov 24 11:04 \u001b[01;34m.ipython\u001b[0m/\r\n",
      "drwxr-xr-x 1 jovyan users       4096 Nov 24 11:04 \u001b[01;34m.jupyter\u001b[0m/\r\n",
      "-rw-r--r-- 1 jovyan users       1707 Nov 24 11:06 lab8.ipynb\r\n",
      "drwxr-xr-x 1 jovyan users       4096 Nov 24 10:59 \u001b[01;34m.local\u001b[0m/\r\n",
      "-rwxrwxrwx 1 root   root  3001659271 Dec 19  2011 \u001b[01;32mtrain_triplets.txt\u001b[0m*\r\n",
      "drwxrwxrwx 1 root   root        4096 Nov 24 10:20 \u001b[34;42myelp-dataset\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyspark\n",
    "%ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abee8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c671133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# since everyone will be using cluster at the same time\n",
    "# let's make sure that everyone has resource. that is why \n",
    "# the configuration uses dynamic resource allocation and\n",
    "# maximum 1 executor \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"1\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2ed6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "songs_df = spark.read.load(\"./train_triplets.txt\",\n",
    "                     format=\"csv\", sep=\"\\t\", inferSchema=\"true\", \n",
    "                     header=\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c11a1cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e39bdeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_df.withColumnRenamed(\"_c0\", \"user\")\\\n",
    "                   .withColumnRenamed(\"_c1\", \"song\")\\\n",
    "                   .withColumnRenamed(\"_c2\", \"play_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e43d3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20887ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "played_more_than_10_times = spark.sql(\"select song from songs where play_count > 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47e0811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2043582"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "played_more_than_10_times.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56979f59",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d419665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/24 11:14:21 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_business.json\")\n",
    "reviews = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_review.json\")\n",
    "users = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_user.json\")\n",
    "business.createOrReplaceTempView(\"business\")\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "users.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72788616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   AZ|56686|\n",
      "|   NV|36312|\n",
      "|   ON|33412|\n",
      "|   NC|14720|\n",
      "|   OH|14697|\n",
      "|   PA|11216|\n",
      "|   QC| 9219|\n",
      "|   AB| 8012|\n",
      "|   WI| 5154|\n",
      "|   IL| 1932|\n",
      "|   SC| 1162|\n",
      "|   NY|   22|\n",
      "|   CA|   19|\n",
      "|   TX|    6|\n",
      "|   FL|    4|\n",
      "|  XGM|    4|\n",
      "|   AL|    3|\n",
      "|   WA|    3|\n",
      "|   CT|    3|\n",
      "|   VA|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query 1\n",
    "spark.sql(\"select state, count(state) as count from business group by state order by count(state) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb8013ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:>                                                         (0 + 8) / 8]\r",
      "\r",
      "[Stage 44:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT category)|\n",
      "+------------------------+\n",
      "|                    2468|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query 2\n",
    "spark.sql(\"\"\"\n",
    "select count(distinct(*)) from (\n",
    "    select explode(split(categories, \\\",\\s*\\\")) as category from business\n",
    ")\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc310ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|         category|count(category)|\n",
      "+-----------------+---------------+\n",
      "|      Restaurants|           2815|\n",
      "|         Shopping|           2416|\n",
      "|    Home Services|           2302|\n",
      "|             Food|           1672|\n",
      "| Health & Medical|           1577|\n",
      "|   Local Services|           1444|\n",
      "|      Restaurants|           1184|\n",
      "|       Automotive|           1164|\n",
      "|    Beauty & Spas|           1115|\n",
      "|    Home Services|            843|\n",
      "+-----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:====================================>                     (5 + 3) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query 3\n",
    "spark.sql(\"\"\"\n",
    "select category, count(category) from \n",
    "    (\n",
    "        select explode(split(categories, \\\",\\s*\\\")) as category \n",
    "        from business where city=\\\"Phoenix\\\"\n",
    "    )\n",
    "group by category order by count(category) desc limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a728ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|friend_count|\n",
      "+------------+\n",
      "|        4166|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Query 4 \n",
    "spark.sql(\"\"\"\n",
    "select \n",
    "    count(*) as friend_count \n",
    "from \n",
    "    users \n",
    "where \n",
    "    size(split(friends, \\\",\\s*\\\")) > 1000\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c87f28e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|         business_id|            rating|            rating|\n",
      "+--------------------+------------------+------------------+\n",
      "|WU6mFeLp8PASoA9jd...|               4.0|               2.2|\n",
      "|45rWYQPlQ4x5cFU0u...|              4.25|               3.0|\n",
      "|MGsV9nuGOr9fxtzJP...|3.4285714285714284|               3.0|\n",
      "|tWjfgVtTD5n01Cq9d...|3.6666666666666665|3.6451612903225805|\n",
      "|JO5_Frcbp9J732VNn...|               2.2|1.2857142857142858|\n",
      "|btQ4Rc7am0KWNIcgt...|               4.5| 2.857142857142857|\n",
      "|FXdAittxUsIR-SWPu...|3.1666666666666665|2.3333333333333335|\n",
      "|Ky67Nk2SLRRaHSYuz...|               5.0|1.3333333333333333|\n",
      "|AiEKjZPj2J3MpnBZk...|               4.0|               3.5|\n",
      "|Ve_RgUoXVEeNnpvmS...|               4.0|               3.5|\n",
      "|p-8PgN7S4VUUXH6y5...|3.3333333333333335|2.2222222222222223|\n",
      "|kZ36LGvnwetEq-seq...| 3.769230769230769|3.6666666666666665|\n",
      "|px2ZZOPzA8-xG_VhE...| 2.533333333333333|1.6964285714285714|\n",
      "|UoPOED2pSAQjf4Gz4...|              3.75|1.3333333333333333|\n",
      "|FJoXrkLaLh76MgHXK...|               4.0| 3.933333333333333|\n",
      "|ROyteoFTxe7i3PZCE...|               5.0|               4.5|\n",
      "|VUknuJV7f9DoqiYds...|3.4705882352941178|3.2941176470588234|\n",
      "|426RL7G7oTyu-f8jF...| 3.611111111111111|               2.8|\n",
      "|1EbdmUMbrS12Dougf...|               3.0|               2.8|\n",
      "|0L3CAgRf8wuH5MjNw...| 4.111111111111111|3.5555555555555554|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 5\n",
    "spark.sql(\"\"\"\n",
    "with business_ratings as (\n",
    "    select \n",
    "        business_id, year(to_date(date)) as year, avg(stars) as rating \n",
    "    from \n",
    "        reviews group by business_id, year(to_date(date))\n",
    "),\n",
    "business_2014 as (\n",
    "    select \n",
    "        business_id, rating \n",
    "    from \n",
    "        business_ratings \n",
    "    where \n",
    "        year=2014\n",
    "),\n",
    "business_2017 as (\n",
    "    select \n",
    "        business_id, rating \n",
    "    from \n",
    "        business_ratings where year=2017\n",
    ")\n",
    "select \n",
    "    business_2014.business_id, business_2014.rating, business_2017.rating \n",
    "from \n",
    "    business_2014 \n",
    "inner join \n",
    "    business_2017 \n",
    "on \n",
    "    business_2014.business_id=business_2017.business_id \n",
    "where \n",
    "    business_2017.rating < business_2014.rating \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8bd73d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  252537|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query 6\n",
    "spark.sql(\n",
    "\"\"\"with p1 as \n",
    "    (SELECT business_id, user_id, MAX(to_date(date))\n",
    "        FROM reviews GROUP BY user_id, business_id),\n",
    "    p2 as (SELECT business_id FROM business WHERE categories LIKE ('%Chinese%') \n",
    "        AND categories LIKE ('%Restaurants%')\n",
    "    ),\n",
    "    p3 as (SELECT p1.user_id \n",
    "        from p1 inner \n",
    "        join p2 \n",
    "        on p2.business_id = p1.business_id)\n",
    "    SELECT COUNT(*) FROM users inner join p3 on p3.user_id = users.user_id\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
